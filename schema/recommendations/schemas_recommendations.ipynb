{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import requests\n",
    "import jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_GOUV_API = \"https://www.data.gouv.fr/api/1\"\n",
    "RECOMMENDATION_SCORE = 50\n",
    "CATALOG_SCHEMAS = 'https://schema.data.gouv.fr/schemas/schemas.json'\n",
    "JSONSCHEMA_URL = \"https://raw.githubusercontent.com/opendatateam/udata-recommendations/master/udata_recommendations/schema.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_from_api_query(\n",
    "    base_query,\n",
    "    next_page='next_page',\n",
    "    ignore_errors=False,\n",
    "    mask=None,\n",
    "):\n",
    "    def get_link_next_page(elem, separated_keys):\n",
    "        result = elem\n",
    "        for k in separated_keys.split('.'):\n",
    "            result = result[k]\n",
    "        return result\n",
    "    # /!\\ only for paginated endpoints\n",
    "    headers = {'X-fields': mask + f',{next_page}'} if mask else None\n",
    "    r = requests.get(base_query, headers=headers)\n",
    "    if not ignore_errors:\n",
    "        r.raise_for_status()\n",
    "    for elem in r.json()[\"data\"]:\n",
    "        yield elem\n",
    "    while get_link_next_page(r.json(), next_page):\n",
    "        r = requests.get(get_link_next_page(r.json(), next_page), headers=headers)\n",
    "        if not ignore_errors:\n",
    "            r.raise_for_status()\n",
    "        for data in r.json()['data']:\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidated_schemas():\n",
    "    \"\"\"Find TableSchema schemas that are consolidated\"\"\"\n",
    "    r = requests.get(CATALOG_SCHEMAS)\n",
    "    schemas = r.json()['schemas']\n",
    "    return { \n",
    "        s['name']: s['consolidation_dataset_id'] \n",
    "        for s in schemas \n",
    "        if s['consolidation_dataset_id'] and s['schema_type'] == 'tableschema'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_for_schema(schema):\n",
    "    \"\"\"Fetch datasets on datagouv with the schema attribute set to a specific value\"\"\"\n",
    "    url = f\"{DATA_GOUV_API}/datasets?schema={schema}\"\n",
    "    r = get_all_from_api_query(\n",
    "        base_query=url,\n",
    "        mask='data{id}'\n",
    "    )\n",
    "    return [d['id'] for d in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recommendation(consolidated_dataset_id, dataset_id):\n",
    "    return {\n",
    "        \"id\": dataset_id,\n",
    "        \"recommendations\": [\n",
    "            {\"id\": consolidated_dataset_id, \"score\": RECOMMENDATION_SCORE}\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_recommendations(recommendations):\n",
    "    \"\"\"\" Validate recommendations according to the JSON schema\"\"\"\n",
    "    r = requests.get(JSONSCHEMA_URL, timeout=10)\n",
    "    r.raise_for_status()\n",
    "    schema = r.json()\n",
    "\n",
    "    jsonschema.validate(recommendations, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etalab/schema-irve\n",
      "etalab/schema-lieux-covoiturage\n",
      "etalab/schema-stationnement\n"
     ]
    }
   ],
   "source": [
    "recommendations = []\n",
    "for schema_id, schema_details in consolidated_schemas().items():\n",
    "    consolidated_dataset_id = schema_details\n",
    "    logger.info(\n",
    "        f\"Working on schema {schema_id}, consolidated on {consolidated_dataset_id}\"\n",
    "    )\n",
    "\n",
    "    dataset_ids = datasets_for_schema(schema_id)\n",
    "    logger.info(f\"Found {len(dataset_ids)} associated with schema {schema_id}\")\n",
    "\n",
    "    recommendations.extend([\n",
    "        build_recommendation(consolidated_dataset_id, d) for d in dataset_ids\n",
    "    ])\n",
    "\n",
    "ids = []\n",
    "recommendations_clean = []\n",
    "for r in recommendations:\n",
    "    if r[\"id\"] not in ids:\n",
    "        ids.append(r[\"id\"])\n",
    "        recommendations_clean.append(r)\n",
    "validate_recommendations(recommendations_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TMP_FOLDER + '/recommendations.json', 'w') as fp:\n",
    "    json.dump(recommendations_clean, fp, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97a2da382d248fff648af7f5651ffebfa1241b000458c068d93c121b6fe556f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
